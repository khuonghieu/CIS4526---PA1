{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this is just a template for PA 1 and the code is for references only.\n",
    "# Feel free to design the pipeline of the *main* function. However, one should keep\n",
    "# the interfaces for the other functions unchanged. Change the returned values of\n",
    "# these functions so that they are consistent with the assignment instructions.\n",
    "# In general, one will only need to add the code below the TO-DO statements to\n",
    "# finish the assignment. Additional import statements can be included when needed.\n",
    "#\n",
    "# For the kNN classifier, one could use existing libraries to compute the pairwise\n",
    "# Euclidean distances between the test and training data, as for-loops in Python\n",
    "# are pretty slow. Other than that, the designs of all functions should be your\n",
    "# original work.\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(test_y, pred_y):\n",
    "\n",
    "    # TO-DO: add your code here\n",
    "    # acc = compute_accuracy(test_y, pred_y)\n",
    "    # test_y is a (num_test,) label vector\n",
    "    # pred_y is a (num_test,) label vector\n",
    "    # acc is a float between 0.0 and 1.0\n",
    "    accuracy = metrics.accuracy_score(test_y, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# calculate Euclidean distance between 2 data points\n",
    "def euclidean_distance(pointA, pointB):    \n",
    "    return np.linalg.norm(pointA - pointB)\n",
    "\n",
    "def test_knn(train_x, train_y, test_x, num_nn):\n",
    "\n",
    "    # TO-DO: add your code here\n",
    "    # train_x is a (num_train, num_dims) data matrix\n",
    "    # train_y is a (num_train,) label vector,\n",
    "    # test_x is a (num_test, num_dims) data matrix,\n",
    "    # num_nn is the number of nearest neighbors for classification.\n",
    "    # pred_y is a (num_test,) label vector\n",
    "    # pred_y = test_knn(train_x, train_y, test_x, num_nn)\n",
    "    \n",
    "    num_test_data = len(test_x)\n",
    "    temp_pred_y = np.zeros(num_test_data)\n",
    "    # loop through testX\n",
    "    # compute Euclidean with trainX\n",
    "    # find K nearest\n",
    "    # distance_to_train store tuple structures (distance, trainData, trainLabel)\n",
    "    # sort & get num_nn neighbors\n",
    "    for i in range(len(test_x)):\n",
    "        distance_to_trainX = []\n",
    "        for j in range(len(train_x)):\n",
    "            dist = euclidean_distance(test_x[i], train_x[j])\n",
    "            distance_to_trainX.append((dist, j))\n",
    "        \n",
    "        distance_to_trainX.sort()\n",
    "        neighbors = distance_to_trainX[:num_nn]\n",
    "        \n",
    "        # take majority\n",
    "        # we use a Counter to find # of datapoints / label\n",
    "        # most_common([n]) - return a list of the n most common elements\n",
    "        num_each_type = Counter()\n",
    "        for member_distance in neighbors:\n",
    "            member_label = train_y[member_distance[1]]\n",
    "            num_each_type[member_label] += 1\n",
    "                \n",
    "        vote_result = num_each_type.most_common(1)[0][0] # get name of most common type\n",
    "        # label current test data ---> put in pred y[i]\n",
    "        temp_pred_y[i] = vote_result;\n",
    "        \n",
    "    return temp_pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6. 20. 10. ... 19. 18.  0.]\n",
      "Accuracy is: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-57d84612f8f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-57d84612f8f5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy is: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-a59abf9d9763>\u001b[0m in \u001b[0;36mcompute_accuracy\u001b[0;34m(test_y, pred_y)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0msimilar_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilar_count\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomparison\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# calculate Euclidean distance between 2 data points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'count' is not defined"
     ]
    }
   ],
   "source": [
    "# compare current lable with one train label\n",
    "def sign_function(weight, train_data):\n",
    "    if np.dot(weight, train_data) < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def convert_label(label, train_y):\n",
    "    for i in range(len(train_y)):\n",
    "        if train_y[i] == label:\n",
    "            train[i] = 1\n",
    "        else:\n",
    "            train[i] = -1\n",
    "    return train_y   \n",
    "    \n",
    "def train_one_weight(train_x, train_y, num_iters):\n",
    "    # Initialize w\n",
    "    # wTx is the (signed) distance of point x to hyperplane w\n",
    "    num_train_data = len(train_x[0])  # grab number of columns\n",
    "    weight = np.zeros(num_train_data + 1).reshape((-1,1))\n",
    "    \n",
    "    for step in range(num_iters): \n",
    "        for j in range(len(train_x)):\n",
    "            current_train_data = train_x[j].reshape((1,-1))\n",
    "            y_n = sign_function(weight,current_train_data)\n",
    "            if (y_n != train_y[j]):\n",
    "                temp_weight = weight + np.dot(y_n, train_x[j])\n",
    "                #if (accuray/error change.......)\n",
    "                #    weight = temp_weight\n",
    "    return weight\n",
    "    \n",
    "#def train_pocket(train_x, train_y, num_iters):\n",
    "\n",
    "    # TO-DO: add your code here\n",
    "    # train_y is a (num_train,) +1/-1 label vector\n",
    "    #  num_iters is the number of iterations for the algorithm\n",
    "    # w is a vector of learned perceptron weights.\n",
    "    # w = train_pocket(train_x, train_y, num_iters)\n",
    "    \n",
    "#    weight_array = [[]]\n",
    "#    for letter in (26_alphabet):\n",
    "#        current_train_y = convert_label(letter, train_y)\n",
    "#        w = train_one_weight(train_x, current_train_y, num_iters)\n",
    "        # add/append to weight_array\n",
    "    \n",
    "#    return weight_array\n",
    "\n",
    "def test_pocket(w, test_x):\n",
    "\n",
    "    # TO-DO: add your code here\n",
    "    # test_x is a (num_test, num_dims) data matrix\n",
    "    # pred_y = test_pocket(w, test_x)\n",
    "    return None\n",
    "\n",
    "def get_id():\n",
    "\n",
    "    # TO-DO: add your code here\n",
    "\n",
    "    return 'tuxddddd'\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Read the data file\n",
    "    szDatasetPath = './letter-recognition.data' # Put this file in the same place as this script\n",
    "    listClasses = []\n",
    "    listAttrs = []\n",
    "    with open(szDatasetPath) as csvFile:\n",
    "        csvReader = csv.reader(csvFile, delimiter=',')\n",
    "        for row in csvReader:\n",
    "            listClasses.append(row[0])\n",
    "            listAttrs.append(list(map(float, row[1:])))\n",
    "\n",
    "    # Generate the mapping from class name to integer IDs\n",
    "    mapCls2Int = dict([(y, x) for x, y in enumerate(sorted(set(listClasses)))])\n",
    "\n",
    "    # Store the dataset with numpy array\n",
    "    dataX = np.array(listAttrs)\n",
    "    dataY = np.array([mapCls2Int[cls] for cls in listClasses])\n",
    "    \n",
    "    # Split the dataset as the training set and test set\n",
    "    nNumTrainingExamples = 15000\n",
    "    trainX = dataX[:nNumTrainingExamples, :]\n",
    "    trainY = dataY[:nNumTrainingExamples]\n",
    "    testX = dataX[nNumTrainingExamples:, :]\n",
    "    testY = dataY[nNumTrainingExamples:]\n",
    "\n",
    "    # TO-DO: add your code here\n",
    "    numNN = 10;\n",
    "    pred_y = test_knn(trainX, trainY, testX, numNN);\n",
    "    print(pred_y);\n",
    "    print(\"Accuracy is: \")\n",
    "    print(compute_accuracy(testY, pred_y))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # test pocket\n",
    "\n",
    "            \n",
    "    return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
